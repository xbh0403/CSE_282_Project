Project title: Uncovering Useful VJ Genes and Associated Epitopes in “Junk” RNA-seq Reads
Group members: Banghua Xu, Lilian Gao, Yuwei Cao
Please see canvas submission for the full report. Thank you!

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Uncovering Useful VJ Genes and Associated Epitopes in “Junk” RNA-seq Reads\\
}

\author{\IEEEauthorblockN{Banghua Xu}
\IEEEauthorblockA{
\textit{}
bax001@ucsd.edu}
\and
\IEEEauthorblockN{Yuwei Cao}
\IEEEauthorblockA{
\textit{}
yuc408@ucsd.edu}
\and
\IEEEauthorblockN{Lilian Gao}
\IEEEauthorblockA{
\textit{}
heg003@ucsd.edu}
}

\maketitle

\begin{abstract}
In this project, we address the biological challenge of identifying the most representative epitopes that are immunoglobin V and J genes obtained from unmapped RNA-seq reads using overlap alignment. By recasting this issue as a classical maximum coverage problem, we explore and evaluate the performance of two different algorithmic solutions: the Brute-force approach and the Greedy Approximation approach. Our evaluation criteria encompass the assessment of time complexity, runtime analysis, as well as the maximum coverage ratio of each method, providing a comprehensive comparison of their effectiveness in solving this complex biological problem.
\end{abstract}

% \begin{IEEEkeywords}
% Maximum Coverage Problem; Immunoglobulin
% \end{IEEEkeywords}

\section{Introduction}
RNA-seq is a widely used method for profiling transcripts in humans. Although it is very useful in studying the transcriptome, one of the initial steps of RNA-seq involves mapping the sequences to a reference genome, which may result in a significant amount of reads being rendered as unmapped or unannotated. These unmapped human transcripts are not completely “junk” reads. Instead, they can be potentially utilized in identifying associations with cancers (Kazemian et al., 2015). In the development of antibodies, immunoglobulin (Ig) V, D and J gene segments undergo rearrangement through recombination and establish B-cell repertoire diversity via somatic hypermutations within the Ig variable regions. Somatic hypermutation introduces variability into the V, D, and J sequences, complicating the accurate representation of BCR diversity. This 'noise' can make it challenging to match observed sequences with canonical ones. Profiling B-cell repertoire is an important component of immune research as somatic hypermutation (SHM) of immunoglobulin variable genes are used as a prognostic marker in diseases related to B-cell dysfunction. Research has also used RNA-seq data for reconstructing immunoglobulin VDJ gene sequences (Islam et al., 2021). 

Moreover, another important aspect of antibody development is the recognition of epitopes. An epitope, also known as an antigenic determinant, is a specific molecular structure on an antigen to which an antibody binds. When B cells encounter antigens, they "recognize" and bind to specific epitopes on the surface of antigen through their antigen receptors, resulting in downstream immune response. Epitopes can be small peptides, carbohydrates, or other molecules. They play a crucial role in immune responses, as they allow antibodies and immune cells to identify and target pathogens (a subset of antigens, specifically refers to a disease-causing microorganism, such as bacteria, viruses, fungi, or parasites) or foreign substances in the body.

In the real application, an important step to develop therapies for autoimmune diseases involves collecting RNA sequences to recover the antibodies that have been generated by patients' immune systems. However, this task is challenging due to the "noisy" nature of the data. As described previously, antibodies are produced by B cells and are prone to somatic hypermutation; it is very likely that some RNA-seq reads from VDJ genes are not aligned to the reference genome. Despite the diversity of antigens, the sequences can appear remarkably similar to one another due to the fact that B cell receptors are generated from a shared genetic sequence. This high similarity amidst diversity presents a challenge in identifying the specific pathogens responsible for an infectious disease in a patient. To address this, researchers usually go through all detected epitopes to separate and recover the real pathogen epitopes. 

For our project, we want to first identify potential antibody genes, especially V and J genes from the unmapped “junk” RNA-seq transcripts using overlap alignment. Each V and J gene is usually associated with one or multiple epitopes. These epitopes can inform us on the specific pathogens the host was exposed to. Then, we want to identify a minimal yet effective set of these real pathogen epitopes by transforming the problem into Set Cover Problem/Maximum Coverage Problem. The goal is to determine the smallest number of epitopes necessary to accurately represent the pathogen causing the disease, minimizing the risk of unnecessary immune reactions while ensuring that the therapy remains effective. This minimal set of epitopes allows for a more precise targeting of the immune response, potentially leading to better therapeutic outcomes for patients with autoimmune diseases.

\section{Methods}

\subsection{Algorithmic challenge overview}

In this project, we’re essentially trying to find a small subset (the most abundant epitopes) from a large set of epitopes (recovered from unmapped RNA-seq transcripts) that can best represent or cover the entire set. This problem can be transformed into Set Cover Problem or Maximum Coverage Problem, which are well-known NP problems. They are considered NP-hard because there is no known algorithm that can solve all instances of these problems efficiently (in polynomial time) for large datasets.

\subsection{Terminology}
$Read_{unmapped}$ is a set of strings with equal length. $V_{genes}$ and $J_{genes}$ are two sets of strings of DNA sequences. Each $v_{gene}$ and $j_{gene}$ is associated with at least one epitope (an epitope is a string of amino acid sequences). $E_{gene}$ is the set of all available epitopes. The VJ database is a dictionary where the keys are either a V gene $v_{gene}$ or a J gene $j_{gene}$, and the corresponding values represent a list of epitopes, $e_{v}$ or $e_{j}$, of $n$ epitope(s), $epitope_{1} \ldots epitope_{n}$, associated with that gene, such that $epitope_{i} \in E_{gene}$. All elements in $V_{genes}$ and $J_{genes}$ can be found in this database.

\subsection{Generation of simulated data}
We performed simulation with functions described as the following:
\begin{enumerate}
    \item \textbf{random\_nt\_sequence} is used to generate random 75bp RNA-seq reads.
    \item \textbf{simulate\_epitopes} is used to randomly generated all epitopes $E_{gene}$ from a pool of amino acids. These epitopes vary in length to reflect natural variation.
    \item \textbf{simulate\_vj\_genes} is used to generate the VJ database. For each $v_{gene}$ and $j_{gene}$, we randomly assign $n$ epitopes ($1 \leq n \leq 3$) from $E_{gene}$, mimicking the genetic diversity found in immune system genes.
    \item \textbf{simulate\_overlap\_reads} is used to combine segments from V genes, D segments (randomly generated nucleotide sequences), and J genes to simulate the recombination process and generate parts of $read_{unmapped}$ strings. 
    \item \textbf{simulate\_random\_reads} is used to generate the other part of $read_{unmapped}$, which has random reads that do not necessarily correspond to any specific genes to represent random DNA sequences that might be encountered in sequencing data. 

\end{enumerate}

The detailed parameters and values of the simulation functions are shown in Table 1. To mitigate the impact of randomness and enhance confidence in our results, we executed the simulation pipelines a total of ten times.

\begin{table}[htbp]
\caption{Parameters for Simulation Functions}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
%\multicolumn{3}{|c|}{\textbf{Parameters for Simulation Functions}} \\

\textbf{\textit{Function}} & \textbf{\textit{Parameter}} & \textbf{\textit{Value}} \\
\hline
random\_nt\_sequence & length & 75 \\
\hline
\multirow{3}{*}{simulate\_vj\_genes} & n\_genes & random.randint(10, 30) \\
 & num\_epitopes & random.randint(1, 4) \\
\hline
\multirow{2}{*}{simulate\_epitopes} & n\_epitopes & random.randint(10, 30)\\
 & len\_epitopes & random.randint(8, 11) \\
\hline
\multirow{2}{*}{simulate\_overlap\_reads} & n\_reads & random.randint(800, 1200) \\
 & len\_read & 75 \\
\hline
simulate\_random\_reads & n\_reads & random.randint(800, 1200) \\
 & len\_read & 75 \\
\hline
\end{tabular}
\label{tab:simulation_parameters}
\end{center}
\end{table}


\subsection{Alignment Strategy}
For each read $read_i \in Read_{unmapped}$, we find the maximum overlap alignment score among all possible $v_{gene}$ and $j_{gene}$, respectively. The overlap score $Score_v$ is calculated by the overlap alignment of $v_gene$ with $read_i$ (dark blue sections in Fig.1), and the overlap score $Score_j$ is calculate by the overlap alignment of $read_i$ with $j_{gene}$ (dark green sections in Fig.2). For each $read_i$ that is aligned with $v_{gene}$ and/or $j_{gene}$ achieving the maximum overlap alignment scores, to ensure that the read can be aligned with both a V gene and a J gene, we took a naive approach to normalize the alignment scores by calculating the Overlap Score $Score_{vj}$ to identify the best combination of V and J genes with the $read_i$. $Score_{vj}$ is equal to the total number of matches in the 2 overlap alignments $\times$ match reward $+$ total number of mismatches in the 2\ overlap alignments $\times$ mismatch penalty. 
We then look up the VJ database to retrieve the lists of epitope(s) $e_v$ and $e_j$ associated with the identified  $v_{gene}$ or $j_{gene}$, respectively. The 2 lists $e_v$ and $e_j$ are combined as a set $e_{vj}$, consisting of all unique epitopes associated with $read_i$. The total number of aligned $read_i$ is denoted as $n$.

\begin{figure}[htbp]
\centering
% Here you can adjust the width or height. For example, to make the image width half of the text width:
\includegraphics[width=0.485\textwidth]{Picture1.png}
% Alternatively, you can adjust the scale of the image:
% \includegraphics[scale=0.5]{final_score_frequency.png}
\caption{Overlap alignments of V/J gene with read.}
\label{fig_1}
\end{figure}

%\subsection{Generation of subsets $S_{epitopes}$}
%For each $read\_string$ that is aligned with  $v_{gene}$ or $j_{gene}$ achieving the maximum overlap alignment score, we look up the VJ database to retrieve the list of epitope(s) $e_{gene}$ associated with either $v_{gene}$ or $j_{gene}$. 

\subsection{Definition} 
We define a set $U$ such that set $U$ contains all aligned read strings: $U ={read_1, read_2 , \ldots, read_n}$. We define a collection $S_{epitopes}$ of $m$ subsets of $U: S_{epitopes} ={S_1, S_2 , \ldots, S_m}$, where $S_i$ represents all the corresponding read strings associated with an epitope, and $S_i \subseteq U$. We denote the union of all elements in a subcollection $S' \subseteq S_{epitopes}$ as $\bigcup_{S_i \in S'} S_i$. We use the notation $|\bigcup_{S_i \in S'} S_i|$ to denote the total number of distinct elements in $|\bigcup_{S_i \in S'} S_i|$.
\vskip 0.2cm
\noindent \textbf{Input:} An integer k, a set $U$ and a collection $S_{epitopes}$ of n subsets $S_{epitopes} = {S_1 , S_2 , \ldots, S_n}$.
\vskip 0.1cm
\noindent \textbf{Output:} Find a subcollection $S' \subseteq S_{epitopes}$ consisting of exactly k subsets, such the total number of covered elements $|\bigcup_{S_i \in S'} S_i|$ is maximized.

\section{Algorithmic approaches}
\subsection{Brute Force Approach}

In the brute force approach, we implemented an exhaustive search to check all possible combinations of the subsets in $S_{epitopes}$. Due to the NP-hard nature of the problem, this method could be very time-intensive for large datasets.

\begin{algorithm}
\caption{Brute Force Maximum Coverage}
\begin{algorithmic}[1]
\State \textbf{Input:} \textit{epitope\_reads\_dict}, a dictionary mapping epitopes to lists of reads
\State \phantom{\textbf{Input:}} \textit{k}, the number of epitopes to select
\State \textbf{Output:} A set of \textit{k} epitopes that maximizes coverage, and the maximum coverage value
\State
% \State \textbf{Function} BruteForceMaxCoverage(\textit{epitope\_reads\_dict}, \textit{k})

\State $max\_coverage \gets 0$
\State $best\_combination \gets \text{an empty set}$
\State Generate all possible combinations of \textit{k} epitopes from \textit{epitope\_reads\_dict}'s keys
\For{\textbf{each} combination}
    \State $combined\_reads \gets \text{an empty set}$
    \For{\textbf{each} epitope in combination}
        \State $combined\_reads.\text{update}($
        \State\hspace{\algorithmicindent} $\textit{epitope\_reads\_dict}[\textit{epitope}]$
        \State $)$
    \EndFor
    \If{$\text{size of } combined\_reads > max\_coverage$}
        \State $max\_coverage \gets \text{size of } combined\_reads$
        \State $best\_combination \gets \text{current combination}$
    \EndIf
\EndFor
\State \Return $best\_combination, max\_coverage$
\end{algorithmic}
\end{algorithm}

\subsection{Greedy Approximation Approach}
In the greedy approximation approach, we implemented a greedy algorithm that iteratively selects the set that covers the most number of uncovered elements. While not optimal, this method would provide a good approximation in a more reasonable time, especially for larger datasets.

\begin{algorithm}
\caption{Greedy Maximum Coverage}
\begin{algorithmic}[1]
\State \textbf{Input:} \textit{epitope\_reads\_dict}, a dictionary mapping epitopes to lists of reads
\State \phantom{\textbf{Input:}} \textit{k}, the number of epitopes to select
\State \textbf{Output:} A set of \textit{k} epitopes that maximizes coverage of reads, and the sum of the best coverage for each selected epitope
\State
% \State \textbf{Function} GreedyMaxCoverage(\textit{epitope\_reads\_dict}, \textit{k})
\State $selected\_epitopes \gets \text{an empty set}$
\State $uncovered\_reads \gets \text{all unique reads from }$
\Statex$\textit{epitope\_reads\_dict}$
\State $best\_coverage\_sum \gets 0$
\For{$i \gets 1$ \textbf{to} $k$}
    \If{$uncovered\_reads = \emptyset$}
        \State \textbf{break}
    \EndIf
    \State $best\_epitope \gets \text{None}$
    \State $best\_coverage \gets 0$
    \For{\textbf{each} $(\textit{epitope}, \textit{reads})$ in $\textit{epitope\_reads\_dict}$}
        \State $coverage \gets \text{size of } (\textit{uncovered\_reads} \cap \textit{reads})$
        \If{$coverage > best\_coverage$}
            \State $best\_coverage \gets coverage$
            \State $best\_epitope \gets \textit{epitope}$
        \EndIf
    \EndFor
    \If{$best\_epitope \neq \text{None}$}
        \State $selected\_epitopes.\text{add}(\textit{best\_epitope})$
        \State $uncovered\_reads \gets uncovered\_reads - \text{set}(\textit{epitope\_reads\_dict}[\textit{best\_epitope}])$
        \State $best\_coverage\_sum \gets best\_coverage\_sum + best\_coverage$
    \EndIf
\EndFor
\State \Return $selected\_epitopes, best\_coverage\_sum$
\end{algorithmic}
\end{algorithm}



\section{Results}
We executed grid search on a dataset with 100 reads to identify the optimal parameters, maximizing the F1 score so that we can effectively distinguish between "real" overlap reads and random reads in a classification setting, while preserving the majority of the information. The remaining results were acquired using this set of optimal parameters.
% We found the following best parameters, $match\_reward=2, mismatch\_penalty=4, indel\_penalty=3, overlap\_match\_score=2, overlap\_mismatch\_score=3, threshold=24$

Fig. 2 displays the mean overlap score derived from conducting the simulation process ten times, aiming to reduce the impact of randomness and enhance the robustness of our findings. Based on this averaged performance, we carefully defined a threshold at 24 that allows us to effectively distinguish between random sequences and genuine sequences that overlap with both V and J genes, ensuring a more precise and confident analysis. As shown in Table 2, the evaluation metrics (accuracy, precision, recall, and f1 score) for the recovery of junk reads are all relatively high, suggesting that we could separate reads that are aligned to V and J genes from random reads. Moreover, we validated that the average ratio of correctly assigned read-epitope pair is 0.59.

To evaluate the performance of brute force and greedy algorithms, we first analyzed time complexity (Table 3), and average runtime (Fig. 3). As shown in Table 3, given $k$ generally small, the brute force algorithm takes exponential time, and the greedy algorithm takes quadratic time. This is also evident in Fig. 3 as the brute force approach's required computation time escalates exponentially with the increase in the number of subsets ($k$), whereas the greedy approximation approach showed a lot slower increase.

We also evaluated the performance of brute force and greedy algorithms by calculating the maximum coverage of epitopes (the output) achieved by these two approaches. Fig. 4 demonstrates that the average maximum coverage of the two approaches are closely matched. Since the brute force algorithm should give us the correct output, Fig. 4 suggests that the greedy approach yielded similar average maximum coverage percentage as the brute force approach. As a conclusion, in terms of the runtime, the greedy approximation algorithm performed better than the brute force algorithm, and in terms of average maximum coverage, it performed as well as the brute force algorithm.


\begin{figure}[htbp]
\centering
% Here you can adjust the width or height. For example, to make the image width half of the text width:
\includegraphics[width=0.485\textwidth]{final_score_frequency_3.png}
% Alternatively, you can adjust the scale of the image:
% \includegraphics[scale=0.5]{final_score_frequency.png}
\caption{Result of overlap alignment}
\label{fig_2}
\end{figure}


\begin{table}[htbp]
\caption{Evaluation Matrics for Junk Read Recovery}
\begin{center}
\begin{tabular}{|c|c|c|c|}
%\multicolumn{4}{|c|}{\textbf{Evaluation Matrics for Junk Read Recovery}} \\
\hline
\textbf{\textit{Accuracy}} & \textbf{\textit{Precision}} & \textbf{\textit{Recall}} & \textbf{\textit{F1}} \\
\hline
0.986 & 0.997 & 0.976 & 0.987 \\
\hline
\end{tabular}
\label{tab:simulation_parameters}
\end{center}
\end{table}

\begin{table}[htbp]
\caption{Time Complexity Analysis}
\begin{center}
\begin{tabular}{|c|c|}
%\multicolumn{2}{|c|}{\textbf{Time Complexibility Analysis}} \\
\hline
 & \\
\multirow{3}{*}\textbf{{Brute-force}} & $O({|epitopes| \choose k} |reads|)$ \\
& \\
\hline
Greedy & $O(|epitopes| \cdot k \cdot |reads|)$ \\
\hline
\end{tabular}
\label{tab:simulation_parameters}
\end{center}
\end{table}


\begin{figure}[htbp]
\centering
% Here you can adjust the width or height. For example, to make the image width half of the text width:
\includegraphics[width=0.485\textwidth]{average_time_by_method_and_k_subsets.png}
% Alternatively, you can adjust the scale of the image:
% \includegraphics[scale=0.5]{final_score_frequency.png}
\caption{Comparison of average run time for brute force vs greedy algorithms.}
\label{fig_3}
\end{figure}

\begin{figure}[htbp]
\centering
% Here you can adjust the width or height. For example, to make the image width half of the text width:
\includegraphics[width=0.485\textwidth]{1.png}
% Alternatively, you can adjust the scale of the image:
% \includegraphics[scale=0.5]{final_score_frequency.png}
\caption{Comparison of max coverage for brute force vs greedy algorithms.}
\label{fig_4}
\end{figure}




\section{Discussion}
In our project, we used simulated data for unmapped RNA-seq reads and VJ database and performed overlap alignment to recover useful potential VJ reads. For these reads, we identified epitopes associated with them and aim to find the most representative subsets of epitopes that cover the most amounts of reads. We transformed this biological challenge of identifying the most representative epitopes into an algorithmic challenge of maximum coverage problem. We implemented two solutions, the brute force method and the greedy approximation method, and evaluated their performance by assessing time complexity, actual runtime of implementations, and the average maximum coverage percentage. We concluded that, between the two methods, not only did the greedy approach run faster than the brute force approach, it also yielded similar output (maximum coverage).

Nonetheless, this project has limitations and further improvement that are worth discussing. For instance, when calculating the overlap score to filter out reads that are not aligned to both V and J genes, we simplified the approach by not differentiating between indels and mismatches. Additionally, we were not able to assess the accuracy of our overlap alignments, focusing solely on calculating the final coverage rate.

Furthermore, our report focused on implementing the algorithms on simulated data due to time constraints. Therefore, one future direction involves utilizing real RNA-seq datasets and incorporating publicly available V and J gene databases. We can select RNA-seq datasets from a particular autoimmune disease that includes a viral infection, such as HIV, and investigate the epitopes generated by various variants.

The development of antibodies involve V, D, and J genes, with the D genes being the most variable and diverse region. For simplicity, we only focused on V and J genes, but for future directions, we can dive deeper into the D genes, and consider D genes in the alignment step. We can also explore the combination of alignment strategies involving V, D, and J genes in order to make the alignment more rigorous.

There are also other more sophisticated algorithms that are used for approximating the maximum coverage problem such as Linear Programming or Genetic Algorithms. Although our simulated datasets were relatively small, if we were to use real datasets that are a lot larger, these algorithms can provide better results.

Exploring machine learning (ML) approaches represents another compelling future direction. By leveraging ML models trained on extensive datasets of epitope sequences and immune response data, we could gain deeper insights into immune recognition processes and antibody response efficacy. Such models might predict epitope effectiveness or antibody response strength, contributing to personalized medicine and vaccine development efficiency. Additionally, ML could improve alignment algorithm optimization and enable precise prediction of gene recombination and novel epitope discovery. 

\section{Code Availability}
The code is publicly available in the following \href{https://github.com/xbh0403/CSE_282_Project}{GitHub} link.

%\section*{References}

\begin{thebibliography}{00}
\bibitem{b1} R. Islam, M. Bilenky, A. P. Weng, J. M. Connors, and M. Hirst, ``CRIS: complete reconstruction of immunoglobulin V-D-J sequences from RNA-seq data,'' \textit{Bioinformatics advances}, vol. 1, no. 1, vbab021, 2021. https://doi.org/10.1093/bioadv/vbab021
\bibitem{b2} M. Kazemian, M. Ren, J. X. Lin, W. Liao, R. Spolski, and W. J. Leonard, ``Comprehensive assembly of novel transcripts from unmapped human RNA-Seq data and their association with cancer,'' \textit{Molecular systems biology}, vol. 11, no. 8, 826, 2015. https://doi.org/10.15252/msb.20156172
\end{thebibliography}

\end{document}

